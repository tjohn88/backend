# ‚úÖ ingest_books_json.py (–≥–æ—Ç–æ–≤—ã–π –ø–æ–¥ –∫–ª—é—á)

import json
import time
import torch
from typing import List
from langchain.docstore.document import Document
from sentence_transformers import SentenceTransformer
from rag_optimizer import ingest_documents

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ ===
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"üì° Using device: {DEVICE}")

print("üì¶ Loading embedding model...")
embedding_model = SentenceTransformer(
    'intfloat/multilingual-e5-large-instruct',
    cache_folder='./intfloat',
    use_auth_token=False,
    local_files_only=True
)

# === –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∫–Ω–∏–≥–∏ ===
def format_book(book: dict) -> str:
    return "\n".join([
        f"–ù–∞–∑–≤–∞–Ω–∏–µ: {book.get('title', '')}",
        f"–ê–≤—Ç–æ—Ä: {book.get('author', '')}",
        f"–ì–†–ù–¢–ò: {book.get('grnti', '')}",
        f"–ë–ë–ö: {book.get('bbk', '')}",
        f"–ê–≤—Ç–æ—Ä—Å–∫–∏–π –∑–Ω–∞–∫: {book.get('author_sign', '')}",
        f"–°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —à–∏—Ñ—Ä: {book.get('systematic_code', '')}",
        f"–†—É–±—Ä–∏–∫–∞: {book.get('subject', '')}",
        f"–î–µ—Ä–∂–∞—Ç–µ–ª—å: {book.get('owners', '')}",
        f"–°—Å—ã–ª–∫–∞: {book.get('pdf_url', '')}",
        f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {book.get('pdf_ocr', '')}"
    ]).strip()

# === –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥ ===
def main():
    start_time = time.time()

    JSON_PATH = "unit.json"
    COLLECTION_NAME = "unit_rag"
    PERSIST_DIR = "./chroma"

    print(f"üìñ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–Ω–∏–≥ –∏–∑ {JSON_PATH}...")
    with open(JSON_PATH, 'r', encoding='utf-8') as f:
        books = json.load(f)

    documents = []
    for book in books:
        text = format_book(book)
        metadata = {
            "title": book.get("title", ""),
            "author": book.get("author", ""),
            "grnti": book.get("grnti", ""),
            "bbk": book.get("bbk", ""),
            "author_sign": book.get("author_sign", ""),
            "systematic_code": book.get("systematic_code", ""),
            "subject": book.get("subject", ""),
            "owners": book.get("owners", ""),
            "pdf_url": book.get("pdf_url", ""),
            "pdf_ocr": book.get("pdf_ocr", "")
        }
        documents.append(Document(page_content=text, metadata=metadata))

    print(f"üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
    texts = [doc.page_content for doc in documents]
    embeddings = embedding_model.encode(texts, convert_to_tensor=False, show_progress_bar=True)

    ingest_documents(
        documents,
        collection_name=COLLECTION_NAME,
        embeddings=embeddings,
        persist_directory=PERSIST_DIR
    )

    elapsed = time.time() - start_time
    print(f"‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed:.2f} —Å–µ–∫.")

if __name__ == "__main__":
    main()
