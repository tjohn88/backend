import os
import requests
from pathlib import Path

INPUT_FOLDER = "input"
OUTPUT_FOLDER = "output"
LLAMA_SERVER_URL = "http://127.0.0.1:8000/completion"

def clean_text_literary_style(text: str) -> str:
    prompt = f"[INST] –¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä. –ü—Ä–µ–æ–±—Ä–∞–∑—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç, –ø–æ–ª—É—á–µ–Ω–Ω—ã–π —á–µ—Ä–µ–∑ OCR, –≤ –≥—Ä–∞–º–æ—Ç–Ω—ã–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω—ã–π —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. –ò—Å–ø—Ä–∞–≤–ª—è–π —Ç–æ–ª—å–∫–æ –æ—à–∏–±–∫–∏, –æ–ø–µ—á–∞—Ç–∫–∏ –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é. –ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è! –ù–µ –ø–µ—Ä–µ–≤–æ–¥–∏ –Ω–∞ –¥—Ä—É–≥–æ–π —è–∑—ã–∫, –Ω–µ –æ–±—ä—è—Å–Ω—è–π, –Ω–µ –¥–æ–ø–æ–ª–Ω—è–π, –Ω–µ —Å–æ–∫—Ä–∞—â–∞–π. –í–æ—Ç —Ç–µ–∫—Å—Ç:\n{text} [/INST]"
    payload = {
        "prompt": prompt,
        "temperature": 0.3,
        "top_p": 0.9,
        "max_tokens": 2048,  # –Ω–µ –Ω–∞–¥–æ –¥–µ–ª–∞—Ç—å –æ–≥—Ä–æ–º–Ω—ã–µ —á–∞–Ω–∫–∏
        "stop": ["</s>"]
    }
    response = requests.post(LLAMA_SERVER_URL, json=payload)
    if response.ok:
        return response.json()["content"].strip()
    else:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Llama Server:", response.text)
        return ""

import difflib

def is_hallucination(orig, edited, threshold=1.5):
    # threshold: –≤–æ —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –¥–ª–∏–Ω–∞ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å
    len_orig = len(orig.split())
    len_edited = len(edited.split())
    if len_edited > len_orig * threshold:
        return True
    # –∏–ª–∏ –µ—Å–ª–∏ –ø—Ä–æ—Ü–µ–Ω—Ç –∏–∑–º–µ–Ω—ë–Ω–Ω—ã—Ö —Å–ª–æ–≤ —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫
    diff = list(difflib.unified_diff(orig.split(), edited.split()))
    if len(diff) > len_orig * 0.8:
        return True
    return False


os.makedirs(OUTPUT_FOLDER, exist_ok=True)
for file in os.listdir(INPUT_FOLDER):
    if file.endswith(".txt"):
        print(f"üöÄ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª: {file}")
        input_path = os.path.join(INPUT_FOLDER, file)
        output_path = os.path.join(OUTPUT_FOLDER, f"{Path(file).stem}_cleaned.txt")

        with open(input_path, "r", encoding="utf-8") as f:
            raw_text = f.read()

        # –†–µ–∂–µ–º –ø–æ –∞–±–∑–∞—Ü–∞–º
        chunks = [chunk.strip() for chunk in raw_text.split("\n") if chunk.strip()]
        cleaned = []

#-------------
        for i, chunk in enumerate(chunks):
            print(f"  ‚úèÔ∏è [{i+1}/{len(chunks)}] –ß–∏—Å—Ç–∏–º –∞–±–∑–∞—Ü...")
            cleaned_chunk = clean_text_literary_style(chunk)
            cleaned.append(cleaned_chunk + "\n")
#            if is_hallucination(chunk, cleaned_chunk):
#                print("‚ö†Ô∏è –ü–û–î–û–ó–†–ò–¢–ï–õ–¨–ù–û: –ú–æ–¥–µ–ª—å —á—Ç–æ-—Ç–æ –Ω–∞–∫–æ–ª–¥–æ–≤–∞–ª–∞!")
#                print("–ë–´–õ–û:", chunk)
#                print("–°–¢–ê–õ–û:", cleaned_chunk)
# –º–æ–∂–Ω–æ –¥–∞–∂–µ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω–æ –≤ suspicious.txt
#            cleaned.append(cleaned_chunk + "\n")

        with open(output_path, "w", encoding="utf-8") as f:
            f.writelines(cleaned)

        print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç: {output_path}\n")
